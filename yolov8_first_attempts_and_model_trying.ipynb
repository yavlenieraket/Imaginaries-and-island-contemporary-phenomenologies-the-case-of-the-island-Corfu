{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvtCrioRHsac",
        "outputId": "19156522-4bc3-44d4-832f-7cbdb86a5afa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.18-py3-none-any.whl (757 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m757.2/757.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.18\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n",
            "100% 21.5M/21.5M [00:00<00:00, 82.7MB/s]\n",
            "Ultralytics YOLOv8.2.18 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data/custom_dataset.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 21.5MB/s]\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2121466  ultralytics.nn.modules.head.Detect           [14, [128, 256, 512]]         \n",
            "Model summary: 225 layers, 11141018 parameters, 11141002 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/map_yolo2/labels/train.cache... 50 images, 6 backgrounds, 0 corrupt: 100% 56/56 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/map_yolo2/labels/val.cache... 13 images, 2 backgrounds, 0 corrupt: 100% 15/15 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000556, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50         0G      2.049      6.337      1.623         55        640: 100% 4/4 [03:02<00:00, 45.62s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:18<00:00, 18.29s/it]\n",
            "                   all         15         62     0.0454      0.293      0.083     0.0615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50         0G      1.853      4.939      1.468         86        640: 100% 4/4 [02:22<00:00, 35.72s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:11<00:00, 11.91s/it]\n",
            "                   all         15         62      0.541      0.238      0.133      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50         0G      1.598      3.661      1.346         91        640: 100% 4/4 [02:10<00:00, 32.67s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 2.750s exceeded\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.89s/it]\n",
            "                   all         15         62       0.52      0.286      0.202      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50         0G      1.534      2.938       1.33        109        640: 100% 4/4 [02:15<00:00, 33.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 2.750s exceeded\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:12<00:00, 12.56s/it]\n",
            "                   all         15         62      0.402      0.273      0.262      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50         0G       1.41       2.71      1.208        166        640: 100% 4/4 [02:10<00:00, 32.58s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 2.750s exceeded\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:11<00:00, 11.07s/it]\n",
            "                   all         15         62      0.282      0.292      0.272      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50         0G      1.298      2.406      1.128         98        640: 100% 4/4 [02:14<00:00, 33.68s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 2.750s exceeded\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:11<00:00, 11.87s/it]\n",
            "                   all         15         62      0.377      0.271      0.251      0.208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50         0G       1.33      2.145      1.171        124        640: 100% 4/4 [02:23<00:00, 35.93s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 2.750s exceeded\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.76s/it]\n",
            "                   all         15         62      0.575      0.195      0.273      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50         0G      1.208      2.331      1.109         98        640: 100% 4/4 [02:10<00:00, 32.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:11<00:00, 11.28s/it]\n",
            "                   all         15         62      0.558      0.211       0.28      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50         0G      1.063      1.955      1.055         65        640: 100% 4/4 [02:09<00:00, 32.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.48s/it]\n",
            "                   all         15         62      0.705      0.218      0.282      0.232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50         0G      1.128      1.716      1.061         98        640: 100% 4/4 [02:09<00:00, 32.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.56s/it]\n",
            "                   all         15         62      0.696      0.179       0.17      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50         0G      1.193      1.883      1.074         66        640: 100% 4/4 [02:09<00:00, 32.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.63s/it]\n",
            "                   all         15         62      0.552      0.159      0.272      0.227\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50         0G      1.154      1.854      1.055         96        640: 100% 4/4 [02:08<00:00, 32.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.52s/it]\n",
            "                   all         15         62      0.694      0.171      0.129      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50         0G      1.139      1.752      1.067         56        640: 100% 4/4 [02:10<00:00, 32.67s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.02s/it]\n",
            "                   all         15         62      0.702       0.15      0.138       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50         0G      1.029      1.438       1.03         67        640: 100% 4/4 [02:08<00:00, 32.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:07<00:00,  7.93s/it]\n",
            "                   all         15         62      0.695      0.161      0.142      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50         0G      1.085      1.531      1.053        108        640: 100% 4/4 [02:10<00:00, 32.67s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:07<00:00,  7.86s/it]\n",
            "                   all         15         62      0.976      0.143       0.14      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50         0G      1.097      1.501      1.026        146        640: 100% 4/4 [02:13<00:00, 33.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.89s/it]\n",
            "                   all         15         62      0.684      0.154      0.138      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50         0G      1.055      1.431      1.057         68        640: 100% 4/4 [02:05<00:00, 31.41s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.12s/it]\n",
            "                   all         15         62      0.848       0.15      0.133      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50         0G     0.9703      1.307      1.022         99        640: 100% 4/4 [02:09<00:00, 32.37s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:07<00:00,  7.79s/it]\n",
            "                   all         15         62      0.864      0.137      0.133      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50         0G     0.9986      1.282      1.001         69        640: 100% 4/4 [02:10<00:00, 32.64s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.28s/it]\n",
            "                   all         15         62      0.862      0.161      0.137      0.111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50         0G      1.097      1.313      1.012        100        640: 100% 4/4 [02:09<00:00, 32.41s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.52s/it]\n",
            "                   all         15         62       0.71      0.157      0.138      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50         0G      1.062      1.268      1.012        108        640: 100% 4/4 [02:09<00:00, 32.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.51s/it]\n",
            "                   all         15         62      0.722      0.156      0.139      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50         0G      1.069      1.222      1.038         89        640: 100% 4/4 [02:11<00:00, 32.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.77s/it]\n",
            "                   all         15         62      0.704      0.142      0.131      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50         0G     0.9702      1.234      1.027         92        640: 100% 4/4 [02:10<00:00, 32.55s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.54s/it]\n",
            "                   all         15         62      0.712      0.145       0.13      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50         0G      1.057       1.16      1.019         86        640: 100% 4/4 [02:09<00:00, 32.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.11s/it]\n",
            "                   all         15         62      0.708      0.157      0.127      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50         0G      1.039      1.256      1.018         67        640: 100% 4/4 [02:14<00:00, 33.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.32s/it]\n",
            "                   all         15         62      0.711      0.135      0.124     0.0932\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50         0G      1.014      1.088      1.018         78        640: 100% 4/4 [02:11<00:00, 32.96s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.76s/it]\n",
            "                   all         15         62      0.742      0.142      0.129     0.0962\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50         0G     0.9562      1.028     0.9733        136        640: 100% 4/4 [02:10<00:00, 32.66s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.49s/it]\n",
            "                   all         15         62      0.736      0.144      0.135      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50         0G     0.9861      1.275     0.9968         88        640: 100% 4/4 [02:21<00:00, 35.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.54s/it]\n",
            "                   all         15         62      0.741      0.142      0.144      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50         0G      1.011      1.155      1.025         88        640: 100% 4/4 [02:15<00:00, 33.78s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.26s/it]\n",
            "                   all         15         62      0.887      0.152      0.147      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50         0G      1.032      1.116      1.004        135        640: 100% 4/4 [02:06<00:00, 31.52s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.32s/it]\n",
            "                   all         15         62      0.864      0.154      0.149      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50         0G      1.058      1.044     0.9809        164        640: 100% 4/4 [02:10<00:00, 32.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.45s/it]\n",
            "                   all         15         62        0.7      0.167      0.148      0.113\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50         0G      1.035      1.107      1.027        131        640: 100% 4/4 [02:09<00:00, 32.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:07<00:00,  7.83s/it]\n",
            "                   all         15         62      0.707      0.157       0.15      0.118\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50         0G       1.05      1.064      0.987         96        640: 100% 4/4 [02:07<00:00, 31.77s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.66s/it]\n",
            "                   all         15         62      0.713      0.164      0.146      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50         0G     0.9341      1.105     0.9803         43        640: 100% 4/4 [02:04<00:00, 31.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.54s/it]\n",
            "                   all         15         62      0.578      0.167      0.142      0.111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50         0G      1.008      1.081      1.021         97        640: 100% 4/4 [02:06<00:00, 31.70s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.70s/it]\n",
            "                   all         15         62      0.585      0.168      0.145       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50         0G     0.9976      1.057     0.9783         92        640: 100% 4/4 [02:10<00:00, 32.59s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.56s/it]\n",
            "                   all         15         62      0.583      0.163      0.146      0.114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50         0G      0.912     0.9858     0.9709         83        640: 100% 4/4 [02:06<00:00, 31.69s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.60s/it]\n",
            "                   all         15         62      0.573      0.157      0.146      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50         0G     0.8863     0.8998     0.9575         87        640: 100% 4/4 [02:08<00:00, 32.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.42s/it]\n",
            "                   all         15         62       0.58      0.159      0.148      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50         0G     0.9497     0.9672     0.9914        122        640: 100% 4/4 [02:05<00:00, 31.27s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.67s/it]\n",
            "                   all         15         62      0.576      0.157      0.144      0.114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50         0G     0.9453     0.9652     0.9804         89        640: 100% 4/4 [02:09<00:00, 32.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.52s/it]\n",
            "                   all         15         62      0.743      0.154      0.157      0.126\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50         0G      1.119      1.284      1.021         41        640: 100% 4/4 [02:08<00:00, 32.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.99s/it]\n",
            "                   all         15         62       0.58      0.157      0.164      0.128\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50         0G      1.127       1.21      1.008         61        640: 100% 4/4 [02:08<00:00, 32.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.83s/it]\n",
            "                   all         15         62       0.59      0.154      0.165      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50         0G      1.083      1.067      1.006         76        640: 100% 4/4 [02:06<00:00, 31.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.56s/it]\n",
            "                   all         15         62      0.581      0.154      0.164      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50         0G      1.089      1.201     0.9742         46        640: 100% 4/4 [02:04<00:00, 31.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.77s/it]\n",
            "                   all         15         62      0.573      0.154      0.177      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50         0G      1.145      1.167      1.029         75        640: 100% 4/4 [02:09<00:00, 32.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.70s/it]\n",
            "                   all         15         62      0.566      0.157      0.185      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50         0G      1.054      1.081      1.005         52        640: 100% 4/4 [02:10<00:00, 32.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.57s/it]\n",
            "                   all         15         62      0.588      0.164      0.199      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50         0G      1.097      1.032     0.9928         36        640: 100% 4/4 [02:07<00:00, 31.90s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.51s/it]\n",
            "                   all         15         62      0.583      0.164      0.198       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50         0G      1.072     0.9849      1.009         51        640: 100% 4/4 [02:06<00:00, 31.69s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.57s/it]\n",
            "                   all         15         62      0.581      0.164      0.157      0.127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50         0G      1.064     0.9774      1.009         64        640: 100% 4/4 [02:07<00:00, 31.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.71s/it]\n",
            "                   all         15         62      0.576      0.164      0.158      0.128\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50         0G      1.088      1.062      1.021         71        640: 100% 4/4 [02:07<00:00, 31.84s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.77s/it]\n",
            "                   all         15         62      0.429      0.164      0.158      0.127\n",
            "\n",
            "50 epochs completed in 1.974 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.18 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 11131002 parameters, 0 gradients, 28.5 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.96s/it]\n",
            "                   all         15         62      0.705      0.218      0.283      0.233\n",
            "                               15         12      0.768          1      0.898      0.799\n",
            "                class2         15         40      0.105      0.275     0.0575     0.0262\n",
            "                class3         15          3          1          0          0          0\n",
            "                class6         15          4     0.0649       0.25     0.0324     0.0114\n",
            "               class10         15          1          1          0      0.995      0.796\n",
            "               class11         15          1          1          0          0          0\n",
            "               class12         15          1          1          0          0          0\n",
            "Speed: 1.8ms preprocess, 542.8ms inference, 0.0ms loss, 78.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
            "Ultralytics YOLOv8.2.18 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 11131002 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/map_yolo2/labels/val.cache... 13 images, 2 backgrounds, 0 corrupt: 100% 15/15 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:14<00:00, 14.69s/it]\n",
            "                   all         15         62      0.705      0.218      0.283      0.233\n",
            "                               15         12      0.768          1      0.898      0.799\n",
            "                class2         15         40      0.105      0.275     0.0575     0.0262\n",
            "                class3         15          3          1          0          0          0\n",
            "                class6         15          4     0.0649       0.25     0.0324     0.0114\n",
            "               class10         15          1          1          0      0.995      0.796\n",
            "               class11         15          1          1          0          0          0\n",
            "               class12         15          1          1          0          0          0\n",
            "Speed: 6.8ms preprocess, 624.6ms inference, 0.0ms loss, 302.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics YOLOv8.2.18 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 11131002 parameters, 0 gradients, 28.5 GFLOPs\n",
            "\n",
            "image 1/78 /content/drive/MyDrive/trymodel/hdm100.png: 640x480 1 , 503.5ms\n",
            "image 2/78 /content/drive/MyDrive/trymodel/hdm101.png: 640x480 1 , 682.9ms\n",
            "image 3/78 /content/drive/MyDrive/trymodel/hdm102.png: 640x480 1 , 419.4ms\n",
            "image 4/78 /content/drive/MyDrive/trymodel/hdm103.png: 640x480 1 , 456.2ms\n",
            "image 5/78 /content/drive/MyDrive/trymodel/hdm104.png: 640x480 1 , 454.4ms\n",
            "image 6/78 /content/drive/MyDrive/trymodel/hdm105.png: 640x480 1 , 475.4ms\n",
            "image 7/78 /content/drive/MyDrive/trymodel/hdm106.png: 640x480 1 , 1 class2, 431.2ms\n",
            "image 8/78 /content/drive/MyDrive/trymodel/hdm107.png: 640x480 1 , 423.2ms\n",
            "image 9/78 /content/drive/MyDrive/trymodel/hdm108.png: 640x480 1 , 1 class2, 414.2ms\n",
            "image 10/78 /content/drive/MyDrive/trymodel/hdm109.png: 640x480 1 , 421.1ms\n",
            "image 11/78 /content/drive/MyDrive/trymodel/hdm110.png: 640x480 (no detections), 431.1ms\n",
            "image 12/78 /content/drive/MyDrive/trymodel/hdm111.png: 640x480 1 , 413.9ms\n",
            "image 13/78 /content/drive/MyDrive/trymodel/hdm112.png: 640x480 1 , 549.9ms\n",
            "image 14/78 /content/drive/MyDrive/trymodel/hdm113.png: 640x480 1 , 677.7ms\n",
            "image 15/78 /content/drive/MyDrive/trymodel/hdm114.png: 640x480 1 , 2 class2s, 688.2ms\n",
            "image 16/78 /content/drive/MyDrive/trymodel/hdm115.png: 640x480 1 , 2 class2s, 412.7ms\n",
            "image 17/78 /content/drive/MyDrive/trymodel/hdm116.png: 640x480 1 , 3 class2s, 1 class6, 474.7ms\n",
            "image 18/78 /content/drive/MyDrive/trymodel/hdm117.png: 640x480 1 , 429.4ms\n",
            "image 19/78 /content/drive/MyDrive/trymodel/hdm118.png: 640x480 1 , 430.8ms\n",
            "image 20/78 /content/drive/MyDrive/trymodel/hdm119.png: 640x480 1 , 1 class2, 426.5ms\n",
            "image 21/78 /content/drive/MyDrive/trymodel/hdm120.png: 640x480 1 , 420.3ms\n",
            "image 22/78 /content/drive/MyDrive/trymodel/hdm121.png: 640x480 1 , 408.3ms\n",
            "image 23/78 /content/drive/MyDrive/trymodel/hdm122.png: 640x480 1 , 415.1ms\n",
            "image 24/78 /content/drive/MyDrive/trymodel/hdm123.png: 640x480 1 , 4 class2s, 1 class6, 420.0ms\n",
            "image 25/78 /content/drive/MyDrive/trymodel/hdm124.png: 640x480 1 , 2 class2s, 1 class9, 410.5ms\n",
            "image 26/78 /content/drive/MyDrive/trymodel/hdm125.png: 640x480 1 , 2 class2s, 517.6ms\n",
            "image 27/78 /content/drive/MyDrive/trymodel/hdm126.png: 640x480 1 , 1 class2, 665.9ms\n",
            "image 28/78 /content/drive/MyDrive/trymodel/hdm127.png: 640x480 1 , 678.1ms\n",
            "image 29/78 /content/drive/MyDrive/trymodel/hdm128.png: 640x480 1 , 25 class2s, 453.7ms\n",
            "image 30/78 /content/drive/MyDrive/trymodel/hdm129.png: 480x640 1 , 1 class2, 454.6ms\n",
            "image 31/78 /content/drive/MyDrive/trymodel/hdm130.png: 640x480 1 , 466.8ms\n",
            "image 32/78 /content/drive/MyDrive/trymodel/hdm131.png: 640x480 1 , 473.4ms\n",
            "image 33/78 /content/drive/MyDrive/trymodel/hdm132.png: 640x480 1 , 464.2ms\n",
            "image 34/78 /content/drive/MyDrive/trymodel/hdm133.png: 640x480 2 s, 7 class2s, 2 class6s, 463.1ms\n",
            "image 35/78 /content/drive/MyDrive/trymodel/hdm134.png: 640x480 1 , 478.7ms\n",
            "image 36/78 /content/drive/MyDrive/trymodel/hdm135.png: 640x480 1 , 498.7ms\n",
            "image 37/78 /content/drive/MyDrive/trymodel/hdm136.png: 640x480 1 , 475.7ms\n",
            "image 38/78 /content/drive/MyDrive/trymodel/hdm36.png: 640x480 1 , 720.8ms\n",
            "image 39/78 /content/drive/MyDrive/trymodel/hdm56.png: 640x480 1 , 696.0ms\n",
            "image 40/78 /content/drive/MyDrive/trymodel/hdm58.png: 640x480 1 , 703.4ms\n",
            "image 41/78 /content/drive/MyDrive/trymodel/hdm62.png: 640x480 1 , 437.9ms\n",
            "image 42/78 /content/drive/MyDrive/trymodel/hdm63.png: 640x480 1 , 3 class2s, 453.8ms\n",
            "image 43/78 /content/drive/MyDrive/trymodel/hdm64.png: 640x480 1 , 441.0ms\n",
            "image 44/78 /content/drive/MyDrive/trymodel/hdm65.png: 640x480 1 , 439.3ms\n",
            "image 45/78 /content/drive/MyDrive/trymodel/hdm66.png: 640x480 1 , 461.6ms\n",
            "image 46/78 /content/drive/MyDrive/trymodel/hdm67.png: 640x480 1 , 462.3ms\n",
            "image 47/78 /content/drive/MyDrive/trymodel/hdm68.png: 640x480 1 , 498.7ms\n",
            "image 48/78 /content/drive/MyDrive/trymodel/hdm69.png: 640x480 1 , 6 class2s, 441.6ms\n",
            "image 49/78 /content/drive/MyDrive/trymodel/hdm70.png: 640x480 1 , 492.1ms\n",
            "image 50/78 /content/drive/MyDrive/trymodel/hdm71.png: 640x480 1 , 5 class2s, 713.7ms\n",
            "image 51/78 /content/drive/MyDrive/trymodel/hdm72.png: 640x480 1 , 1 class2, 682.1ms\n",
            "image 52/78 /content/drive/MyDrive/trymodel/hdm73.png: 640x480 1 , 727.0ms\n",
            "image 53/78 /content/drive/MyDrive/trymodel/hdm74.png: 640x480 1 , 467.5ms\n",
            "image 54/78 /content/drive/MyDrive/trymodel/hdm75.png: 640x480 1 , 1 class2, 431.7ms\n",
            "image 55/78 /content/drive/MyDrive/trymodel/hdm76.png: 640x480 1 , 1 class2, 435.9ms\n",
            "image 56/78 /content/drive/MyDrive/trymodel/hdm77.png: 640x480 1 , 1 class2, 1 class11, 451.7ms\n",
            "image 57/78 /content/drive/MyDrive/trymodel/hdm78.png: 640x480 2 s, 2 class2s, 1 class6, 478.9ms\n",
            "image 58/78 /content/drive/MyDrive/trymodel/hdm79.png: 640x480 1 , 1 class2, 472.5ms\n",
            "image 59/78 /content/drive/MyDrive/trymodel/hdm80.png: 640x480 2 s, 7 class2s, 441.2ms\n",
            "image 60/78 /content/drive/MyDrive/trymodel/hdm81.png: 640x480 1 , 1 class2, 448.1ms\n",
            "image 61/78 /content/drive/MyDrive/trymodel/hdm82.png: 640x480 1 , 429.6ms\n",
            "image 62/78 /content/drive/MyDrive/trymodel/hdm83.png: 640x480 1 , 673.1ms\n",
            "image 63/78 /content/drive/MyDrive/trymodel/hdm84.png: 640x480 1 class2, 672.2ms\n",
            "image 64/78 /content/drive/MyDrive/trymodel/hdm85.png: 640x480 1 , 1 class2, 721.7ms\n",
            "image 65/78 /content/drive/MyDrive/trymodel/hdm86.png: 640x480 1 , 437.2ms\n",
            "image 66/78 /content/drive/MyDrive/trymodel/hdm87.png: 640x480 1 , 1 class2, 1 class6, 418.1ms\n",
            "image 67/78 /content/drive/MyDrive/trymodel/hdm88.png: 640x480 (no detections), 455.9ms\n",
            "image 68/78 /content/drive/MyDrive/trymodel/hdm89.png: 640x480 (no detections), 459.4ms\n",
            "image 69/78 /content/drive/MyDrive/trymodel/hdm90.png: 640x480 1 , 464.4ms\n",
            "image 70/78 /content/drive/MyDrive/trymodel/hdm91.png: 640x480 1 , 434.2ms\n",
            "image 71/78 /content/drive/MyDrive/trymodel/hdm92.png: 640x480 1 , 437.1ms\n",
            "image 72/78 /content/drive/MyDrive/trymodel/hdm93.png: 640x480 1 , 424.1ms\n",
            "image 73/78 /content/drive/MyDrive/trymodel/hdm94.png: 640x480 1 , 435.0ms\n",
            "image 74/78 /content/drive/MyDrive/trymodel/hdm95.png: 640x480 1 , 439.2ms\n",
            "image 75/78 /content/drive/MyDrive/trymodel/hdm96.png: 640x480 1 , 1 class6, 683.5ms\n",
            "image 76/78 /content/drive/MyDrive/trymodel/hdm97.png: 640x480 1 , 699.7ms\n",
            "image 77/78 /content/drive/MyDrive/trymodel/hdm98.png: 640x480 3 s, 2 class2s, 1 class6, 435.4ms\n",
            "image 78/78 /content/drive/MyDrive/trymodel/hdm99.png: 640x480 1 , 418.6ms\n",
            "Speed: 4.0ms preprocess, 498.9ms inference, 31.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Install YOLOv8 and dependencies\n",
        "!pip install ultralytics opencv-python-headless\n",
        "\n",
        "# Step 3: Set up directories and paths\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define the path to your dataset in Google Drive\n",
        "drive_path = '/content/drive/MyDrive/map_yolo2'\n",
        "\n",
        "# Create directories for train and val\n",
        "os.makedirs(f'{drive_path}/images/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/images/val', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/val', exist_ok=True)\n",
        "\n",
        "# Function to split the dataset\n",
        "def train_test_split(images_dir, labels_dir, split_ratio=0.8):\n",
        "    images = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    split_idx = int(len(images) * split_ratio)\n",
        "    train_images = images[:split_idx]\n",
        "    val_images = images[split_idx:]\n",
        "\n",
        "    for img in train_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/train', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')  # Assuming labels have the same name as images but with .txt extension\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/train', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "    for img in val_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/val', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/val', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "# Split the dataset\n",
        "train_test_split(f'{drive_path}/images', f'{drive_path}/labels')\n",
        "\n",
        "# Ensure the 'data' directory exists\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Create a YAML configuration file for your dataset\n",
        "data_config = f\"\"\"\n",
        "train: {drive_path}/images/train\n",
        "val: {drive_path}/images/val\n",
        "\n",
        "nc: 14  # Update with the correct number of classes\n",
        "names: ['island's borders', 'objects on island']  # Update with your class names\n",
        "\"\"\"\n",
        "\n",
        "# Save the configuration to a file\n",
        "with open('data/custom_dataset.yaml', 'w') as f:\n",
        "    f.write(data_config)\n",
        "\n",
        "# Step 4: Train the YOLOv8 Model\n",
        "!yolo task=detect mode=train data=data/custom_dataset.yaml model=yolov8s.pt epochs=50 imgsz=640 batch=16\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "!yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=data/custom_dataset.yaml\n",
        "\n",
        "# Step 6: Use the Trained Model for Inference\n",
        "!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=/content/drive/MyDrive/trymodel imgsz=640 conf=0.25\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Install YOLOv8 and dependencies\n",
        "!pip install ultralytics opencv-python-headless\n",
        "\n",
        "# Step 3: Set up directories and paths\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define the path to your dataset in Google Drive\n",
        "drive_path = '/content/drive/MyDrive/YOLOV8'\n",
        "\n",
        "# Create directories for train and val\n",
        "os.makedirs(f'{drive_path}/images/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/images/val', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/val', exist_ok=True)\n",
        "\n",
        "# Function to split the dataset\n",
        "def train_test_split(images_dir, labels_dir, split_ratio=0.8):\n",
        "    images = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    split_idx = int(len(images) * split_ratio)\n",
        "    train_images = images[:split_idx]\n",
        "    val_images = images[split_idx:]\n",
        "\n",
        "    for img in train_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/train', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')  # Assuming labels have the same name as images but with .txt extension\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/train', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "    for img in val_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/val', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/val', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "# Split the dataset\n",
        "train_test_split(f'{drive_path}/images', f'{drive_path}/labels')\n",
        "\n",
        "# Ensure the 'data' directory exists\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Create a YAML configuration file for your dataset\n",
        "data_config = f\"\"\"\n",
        "train: {drive_path}/images/train\n",
        "val: {drive_path}/images/val\n",
        "\n",
        "nc: 4  # Update with the correct number of classes\n",
        "names: ['beaches', 'island', 'names_and_descriptions', 'signs']  # Update with your class names\n",
        "\"\"\"\n",
        "\n",
        "# Save the configuration to a file\n",
        "with open('data/custom_dataset.yaml', 'w') as f:\n",
        "    f.write(data_config)\n",
        "\n",
        "# Step 4: Train the YOLOv8 Model\n",
        "!yolo task=detect mode=train data=data/custom_dataset.yaml model=yolov8s.pt epochs=50 imgsz=640 batch=16\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "!yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=data/custom_dataset.yaml\n",
        "\n",
        "# Step 6: Use the Trained Model for Inference\n",
        "!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=/content/drive/MyDrive/tryyolo8 imgsz=640 conf=0.25"
      ],
      "metadata": {
        "id": "K1cqC3nA9iOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Install YOLOv8 and dependencies\n",
        "!pip install ultralytics opencv-python-headless\n",
        "\n",
        "# Step 3: Set up directories and paths\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define the path to your dataset in Google Drive\n",
        "drive_path = '/content/drive/MyDrive/YOLOV8'\n",
        "\n",
        "# Create directories for train and val\n",
        "os.makedirs(f'{drive_path}/images/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/images/val', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/val', exist_ok=True)\n",
        "\n",
        "# Function to split the dataset\n",
        "def train_test_split(images_dir, labels_dir, split_ratio=0.8):\n",
        "    images = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    split_idx = int(len(images) * split_ratio)\n",
        "    train_images = images[:split_idx]\n",
        "    val_images = images[split_idx:]\n",
        "\n",
        "    for img in train_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/train', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')  # Assuming labels have the same name as images but with .txt extension\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/train', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "    for img in val_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/val', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/val', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "# Split the dataset\n",
        "train_test_split(f'{drive_path}/images', f'{drive_path}/labels')\n",
        "\n",
        "# Ensure the 'data' directory exists\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Create a YAML configuration file for your dataset\n",
        "data_config = f\"\"\"\n",
        "train: {drive_path}/images/train\n",
        "val: {drive_path}/images/val\n",
        "\n",
        "nc: 4  # Update with the correct number of classes\n",
        "names: ['beaches', 'island', 'names_and_descriptions', 'signs']  # Update with your class names\n",
        "\"\"\"\n",
        "\n",
        "# Save the configuration to a file\n",
        "with open('data/custom_dataset.yaml', 'w') as f:\n",
        "    f.write(data_config)\n",
        "\n",
        "# Step 4: Train the YOLOv8 Model\n",
        "!yolo task=detect mode=train data=data/custom_dataset.yaml model=yolov8s.pt epochs=50 imgsz=640 batch=16\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "!yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=data/custom_dataset.yaml\n",
        "\n",
        "# Step 6: Use the Trained Model for Inference\n",
        "!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=/content/drive/MyDrive/tryyolo8 imgsz=640 conf=0.25"
      ],
      "metadata": {
        "id": "w74tI1kE9nNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCYhWoVE9OVE",
        "outputId": "12f47e86-b618-43a4-e371-04aa074c74fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 556, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/model.py\", line 23, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 152, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 241, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 806, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 732, in torch_safe_load\n",
            "    ckpt = torch.load(file, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 997, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 444, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 425, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/detect/train/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Use the Trained Model for Inference\n",
        "!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=/content/drive/MyDrive/trymodel imgsz=640 conf=0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kibN7EmLxnCe",
        "outputId": "2c540392-ac6a-4aa6-ca70-ffebc925a3de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.18-py3-none-any.whl (757 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m757.2/757.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.18\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n",
            "100% 21.5M/21.5M [00:00<00:00, 150MB/s] \n",
            "Ultralytics YOLOv8.2.18 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=data/custom_dataset.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 12.0MB/s]\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2121466  ultralytics.nn.modules.head.Detect           [14, [128, 256, 512]]         \n",
            "Model summary: 225 layers, 11141018 parameters, 11141002 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/map_yolo2/labels/train.cache... 50 images, 6 backgrounds, 0 corrupt: 100% 56/56 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/map_yolo2/labels/val.cache... 13 images, 2 backgrounds, 0 corrupt: 100% 15/15 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000556, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100         0G      2.049      6.337      1.623         55        640: 100% 4/4 [03:06<00:00, 46.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:16<00:00, 16.63s/it]\n",
            "                   all         15         62     0.0454      0.293      0.083     0.0615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100         0G      1.853      4.933      1.468         86        640: 100% 4/4 [02:26<00:00, 36.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:11<00:00, 11.88s/it]\n",
            "                   all         15         62      0.541      0.238      0.137      0.105\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100         0G      1.595      3.649      1.346         91        640: 100% 4/4 [02:21<00:00, 35.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 2.750s exceeded\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:12<00:00, 12.95s/it]\n",
            "                   all         15         62      0.517      0.286      0.178      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100         0G      1.538      2.922      1.323        109        640: 100% 4/4 [02:21<00:00, 35.44s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 2.750s exceeded\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:13<00:00, 13.03s/it]\n",
            "                   all         15         62      0.236      0.283      0.169      0.148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100         0G      1.393       2.71      1.204        166        640: 100% 4/4 [02:22<00:00, 35.60s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/1 [00:00<?, ?it/s]WARNING âš ï¸ NMS time limit 2.750s exceeded\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:12<00:00, 12.84s/it]\n",
            "                   all         15         62      0.137      0.292      0.274      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100         0G       1.29      2.409      1.126         98        640: 100% 4/4 [02:20<00:00, 35.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:12<00:00, 12.63s/it]\n",
            "                   all         15         62      0.214      0.149      0.276      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100         0G       1.32      2.167      1.164        124        640: 100% 4/4 [02:19<00:00, 34.94s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:12<00:00, 12.52s/it]\n",
            "                   all         15         62      0.531      0.211      0.279      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100         0G       1.19      2.316        1.1         98        640: 100% 4/4 [02:21<00:00, 35.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:11<00:00, 11.04s/it]\n",
            "                   all         15         62      0.553      0.207      0.207      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100         0G      1.025      1.926      1.042         65        640: 100% 4/4 [02:20<00:00, 35.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.36s/it]\n",
            "                   all         15         62      0.542      0.208      0.268      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100         0G      1.121      1.715      1.057         98        640: 100% 4/4 [02:21<00:00, 35.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.53s/it]\n",
            "                   all         15         62      0.553      0.143        0.2       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/100         0G      1.178      1.841      1.064         66        640: 100% 4/4 [02:19<00:00, 34.82s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:11<00:00, 11.24s/it]\n",
            "                   all         15         62       0.41      0.152      0.275      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/100         0G      1.146      1.783      1.056         96        640: 100% 4/4 [02:23<00:00, 35.95s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.83s/it]\n",
            "                   all         15         62      0.552      0.152      0.143      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/100         0G      1.148      1.736      1.063         56        640: 100% 4/4 [02:22<00:00, 35.72s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.99s/it]\n",
            "                   all         15         62      0.713      0.148       0.15      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/100         0G      1.044      1.396      1.039         67        640: 100% 4/4 [02:18<00:00, 34.66s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.66s/it]\n",
            "                   all         15         62      0.726      0.149      0.143      0.117\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/100         0G      1.079      1.477      1.046        108        640: 100% 4/4 [02:17<00:00, 34.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:08<00:00,  8.46s/it]\n",
            "                   all         15         62      0.701      0.161      0.142      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/100         0G      1.096       1.46      1.031        146        640: 100% 4/4 [02:19<00:00, 34.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:13<00:00, 13.18s/it]\n",
            "                   all         15         62      0.854      0.161      0.139      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/100         0G       1.06      1.377      1.059         68        640: 100% 4/4 [02:20<00:00, 35.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.13s/it]\n",
            "                   all         15         62      0.696      0.152      0.136      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/100         0G     0.9615      1.246      1.022         99        640: 100% 4/4 [02:16<00:00, 34.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.49s/it]\n",
            "                   all         15         62      0.856       0.14      0.126     0.0975\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/100         0G     0.9689      1.278     0.9984         69        640: 100% 4/4 [02:19<00:00, 34.87s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:10<00:00, 10.51s/it]\n",
            "                   all         15         62       0.88      0.144      0.135     0.0969\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/100         0G      1.121       1.34      1.032        100        640: 100% 4/4 [02:17<00:00, 34.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:09<00:00,  9.14s/it]\n",
            "                   all         15         62      0.877      0.144      0.139        0.1\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/4 [00:06<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 583, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 674, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 199, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 371, in _do_train\n",
            "    self.loss, self.loss_items = self.model(batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 88, in forward\n",
            "    return self.loss(x, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 266, in loss\n",
            "    preds = self.forward(batch[\"img\"]) if preds is None else preds\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 89, in forward\n",
            "    return self.predict(x, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 107, in predict\n",
            "    return self._predict_once(x, profile, visualize, embed)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 128, in _predict_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/block.py\", line 231, in forward\n",
            "    return self.cv2(torch.cat(y, 1))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/modules/conv.py\", line 50, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Install YOLOv8 and dependencies\n",
        "!pip install ultralytics opencv-python-headless\n",
        "\n",
        "# Step 3: Set up directories and paths\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define the path to your dataset in Google Drive\n",
        "drive_path = '/content/drive/MyDrive/map_yolo2'\n",
        "\n",
        "# Create directories for train and val\n",
        "os.makedirs(f'{drive_path}/images/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/images/val', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/val', exist_ok=True)\n",
        "\n",
        "# Function to split the dataset\n",
        "def train_test_split(images_dir, labels_dir, split_ratio=0.8):\n",
        "    images = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    split_idx = int(len(images) * split_ratio)\n",
        "    train_images = images[:split_idx]\n",
        "    val_images = images[split_idx:]\n",
        "\n",
        "    for img in train_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/train', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')  # Assuming labels have the same name as images but with .txt extension\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/train', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "    for img in val_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/val', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/val', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "# Split the dataset\n",
        "train_test_split(f'{drive_path}/images', f'{drive_path}/labels')\n",
        "\n",
        "# Ensure the 'data' directory exists\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Create a YAML configuration file for your dataset\n",
        "data_config = f\"\"\"\n",
        "train: {drive_path}/images/train\n",
        "val: {drive_path}/images/val\n",
        "\n",
        "nc: 14  # Update with the correct number of classes\n",
        "names: ['', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']  # Update with your class names\n",
        "\"\"\"\n",
        "\n",
        "# Save the configuration to a file\n",
        "with open('data/custom_dataset.yaml', 'w') as f:\n",
        "    f.write(data_config)\n",
        "\n",
        "# Step 4: Train the YOLOv8 Model\n",
        "!yolo task=detect mode=train data=data/custom_dataset.yaml model=yolov8s.pt epochs=100 imgsz=640 batch=16\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "!yolo task=detect mode=val model=runs/detect/train3/weights/best.pt data=data/custom_dataset.yaml\n",
        "\n",
        "# Step 6: Use the Trained Model for Inference\n",
        "!yolo task=detect mode=predict model=runs/detect/train3/weights/best.pt source=/content/drive/MyDrive/trymodel imgsz=640 conf=0.25\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0riqQKnxXq2",
        "outputId": "60499b48-af02-4a78-a4ef-d0e6524b0f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "ls: cannot access 'runs/detect/train3': No such file or directory\n",
            "File does not exist. Check the path and filename.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# Check the contents of the training directory\n",
        "!ls runs/detect/train3\n",
        "\n",
        "\n",
        "# Verify the file exists\n",
        "file_path = 'runs/detect/train3/'\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File exists\")\n",
        "else:\n",
        "    print(\"File does not exist. Check the path and filename.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aqvB1f0uakT",
        "outputId": "36ccc024-1eae-445e-c328-a346e44f76a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: yolo: command not found\n",
            "/bin/bash: line 1: yolo: command not found\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Evaluate the Model\n",
        "!yolo task=detect mode=val model=runs/detect/train3/weights/best.pt data=data/custom_dataset.yaml\n",
        "\n",
        "# Step 6: Use the Trained Model for Inference\n",
        "!yolo task=detect mode=predict model=runs/detect/train3/weights/best.pt source=/content/drive/MyDrive/trymodel imgsz=640 conf=0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8K1QbArVyQl",
        "outputId": "7d62adcb-7f41-4cf7-ddb7-fc890479a8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.18)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.40)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Ultralytics YOLOv8.2.18 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/map_yolo2/data/custom_dataset.yaml, epochs=100, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 517, in get_dataset\n",
            "    data = check_det_dataset(self.args.data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/utils.py\", line 269, in check_det_dataset\n",
            "    file = check_file(dataset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py\", line 506, in check_file\n",
            "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
            "FileNotFoundError: '/content/drive/MyDrive/map_yolo2/data/custom_dataset.yaml' does not exist\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 583, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 655, in train\n",
            "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 130, in __init__\n",
            "    self.trainset, self.testset = self.get_dataset()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 521, in get_dataset\n",
            "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error âŒ {e}\")) from e\n",
            "RuntimeError: Dataset '/content/drive/MyDrive/map_yolo2/data/custom_dataset.yaml' error âŒ '/content/drive/MyDrive/map_yolo2/data/custom_dataset.yaml' does not exist\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 556, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/model.py\", line 23, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 152, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 241, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 806, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 732, in torch_safe_load\n",
            "    ckpt = torch.load(file, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 997, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 444, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 425, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/detect/train/weights/best.pt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 556, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/model.py\", line 23, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 152, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 241, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 806, in attempt_load_one_weight\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\", line 732, in torch_safe_load\n",
            "    ckpt = torch.load(file, map_location=\"cpu\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 997, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 444, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 425, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'runs/detect/train/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Install YOLOv8 and dependencies\n",
        "!pip install ultralytics opencv-python-headless\n",
        "\n",
        "# Step 3: Set up directories and paths\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define the path to your dataset in Google Drive\n",
        "drive_path = '/content/drive/MyDrive/map_yolo2'\n",
        "\n",
        "# Create directories for train and val\n",
        "os.makedirs(f'{drive_path}/images/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/images/val', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/train', exist_ok=True)\n",
        "os.makedirs(f'{drive_path}/labels/val', exist_ok=True)\n",
        "\n",
        "# Function to split the dataset\n",
        "def train_test_split(images_dir, labels_dir, split_ratio=0.8):\n",
        "    images = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    split_idx = int(len(images) * split_ratio)\n",
        "    train_images = images[:split_idx]\n",
        "    val_images = images[split_idx:]\n",
        "\n",
        "    for img in train_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/train', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')  # Assuming labels have the same name as images but with .txt extension\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/train', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "    for img in val_images:\n",
        "        try:\n",
        "            shutil.move(os.path.join(images_dir, img), os.path.join(f'{images_dir}/val', img))\n",
        "            label = img.replace('.png', '.txt').replace('.jpg', '.txt')\n",
        "            shutil.move(os.path.join(labels_dir, label), os.path.join(f'{labels_dir}/val', label))\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label for {img} not found, skipping.\")\n",
        "\n",
        "# Split the dataset\n",
        "train_test_split(f'{drive_path}/images', f'{drive_path}/labels')\n",
        "\n",
        "# Ensure the 'data' directory exists\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Create a YAML configuration file for your dataset\n",
        "data_config = f\"\"\"\n",
        "train: /content/drive/MyDrive/map_yolo2/images/train\n",
        "val: /content/drive/MyDrive/map_yolo2/images/val\n",
        "\n",
        "nc: 14\n",
        "names: ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']\n",
        "nc: 14  # Update with the correct number of classes\n",
        "names: ['', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'class10', 'class11', 'class12', 'class13', 'class14']  # Update with your class names\n",
        "\"\"\"\n",
        "\n",
        "# Save the configuration to a file\n",
        "with open('data/custom_dataset.yaml', 'w') as f:\n",
        "    f.write(data_config)\n",
        "\n",
        "# Step 4: Train the YOLOv8 Model\n",
        "!yolo task=detect mode=train model=yolov8s.pt data=/content/drive/MyDrive/map_yolo2/data/custom_dataset.yaml epochs=100 imgsz=640 batch=32 name=train optimizer=AdamW\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "!yolo task=detect mode=val model=runs/detect/train/weights/best.pt data=data/custom_dataset.yaml\n",
        "\n",
        "# Step 6: Use the Trained Model for Inference\n",
        "!yolo task=detect mode=predict model=runs/detect/train/weights/best.pt source=/content/drive/MyDrive/trymodel imgsz=640 conf=0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xRMFvO0Q-SAM",
        "outputId": "a2e01a61-d1f1-4b70-dfe7-af86486e3536"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_8e5d6c34-17ce-4626-8595-91cf9438debb\", \"20240521_Tuesday_21_detected_by_class.zip\", 22)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "80ZIgtULByB3",
        "outputId": "0ef15f2e-acad-4ed5-e28f-e0394771d0f4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_101a6a08-601b-470b-a126-ca76cac102aa\", \"detected_by_class.zip\", 22)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "\n",
        "# Directory containing the results\n",
        "results_dir = '/content/runs/detect/predict'\n",
        "\n",
        "# Directory to store images by class\n",
        "output_base_dir = '/content/detected_by_class'\n",
        "os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "# Dictionary to hold detection counts by class\n",
        "detection_counts = defaultdict(int)\n",
        "\n",
        "# Function to extract and save images by class\n",
        "def extract_images_by_class(results_dir, output_base_dir):\n",
        "    for file in os.listdir(results_dir):\n",
        "        if file.endswith('.txt'):\n",
        "            with open(os.path.join(results_dir, file), 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                detected_classes = set()\n",
        "                for line in lines:\n",
        "                    class_id = line.split()[0]  # Assuming the class number is the first element\n",
        "                    detected_classes.add(class_id)\n",
        "                    detection_counts[class_id] += 1\n",
        "\n",
        "                # Copy image to respective class directories\n",
        "                for class_id in detected_classes:\n",
        "                    class_dir = os.path.join(output_base_dir, f'class_{class_id}')\n",
        "                    os.makedirs(class_dir, exist_ok=True)\n",
        "                    image_file = file.replace('.txt', '.png')  # Assuming the image files are .jpg\n",
        "                    shutil.copy(os.path.join(results_dir, image_file), class_dir)\n",
        "\n",
        "# Extract and save images by class\n",
        "extract_images_by_class(results_dir, output_base_dir)\n",
        "\n",
        "# Print detection counts by class\n",
        "for class_id, count in detection_counts.items():\n",
        "    print(f'Class {class_id}: {count} detections')\n",
        "\n",
        "# Zip the directory containing images categorized by class\n",
        "zip_filename = 'detected_by_class.zip'\n",
        "zip_path = os.path.join('/content', zip_filename)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, dirs, files in os.walk(output_base_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), output_base_dir))\n",
        "\n",
        "# Download the zipped file\n",
        "colab_files.download(zip_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-GPGkv-uMZt-",
        "outputId": "76e05b83-b039-47d6-c279-ac3098b6ba6d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_7ed2abe8-e063-4470-89e3-37982470c9c2\", \"20240521_Tuesday_21_class2_images.zip\", 22)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "from google.colab import files as colab_files\n",
        "\n",
        "# Directory containing the results\n",
        "results_dir = '/content/runs/detect/predict'\n",
        "\n",
        "# Directory to store cropped images of class 2 objects\n",
        "class2_images_path = '/content/class2_images'\n",
        "os.makedirs(class2_images_path, exist_ok=True)\n",
        "\n",
        "# Function to extract and save cropped images of class 2 objects\n",
        "def extract_class2_objects(results_dir, save_dir):\n",
        "    detection_counts = defaultdict(int)\n",
        "    for file in os.listdir(results_dir):\n",
        "        if file.endswith('.txt'):\n",
        "            image_file = file.replace('.txt', '.png')\n",
        "            image_path = os.path.join(results_dir, image_file)\n",
        "            with open(os.path.join(results_dir, file), 'r') as f:\n",
        "                lines = f.readlines()\n",
        "                for line in lines:\n",
        "                    elements = line.split()\n",
        "                    class_id = elements[0]  # Assuming the class number is the first element\n",
        "                    if class_id == '2':  # Class 2 detection\n",
        "                        x_center, y_center, width, height = map(float, elements[1:5])\n",
        "\n",
        "                        # Open the image\n",
        "                        with Image.open(image_path) as img:\n",
        "                            img_width, img_height = img.size\n",
        "\n",
        "                            # Calculate the bounding box coordinates\n",
        "                            left = (x_center - width / 2) * img_width\n",
        "                            top = (y_center - height / 2) * img_height\n",
        "                            right = (x_center + width / 2) * img_width\n",
        "                            bottom = (y_center + height / 2) * img_height\n",
        "\n",
        "                            # Crop the image\n",
        "                            cropped_img = img.crop((left, top, right, bottom))\n",
        "\n",
        "                            # Save the cropped image\n",
        "                            cropped_img_filename = f\"{os.path.splitext(image_file)[0]}_class2_{detection_counts[class_id]}.png\"\n",
        "                            cropped_img_path = os.path.join(save_dir, cropped_img_filename)\n",
        "                            cropped_img.save(cropped_img_path)\n",
        "\n",
        "                            detection_counts[class_id] += 1\n",
        "\n",
        "# Extract and save cropped images of class 2 objects\n",
        "extract_class2_objects(results_dir, class2_images_path)\n",
        "\n",
        "# Print detection counts by class\n",
        "for class_id, count in detection_counts.items():\n",
        "    print(f'Class {class_id}: {count} detections')\n",
        "\n",
        "# Zip the directory containing cropped images of class 2 objects\n",
        "strDate = datetime.now().strftime(\"%Y%m%d\")\n",
        "day = datetime.now().strftime(\"%A\")\n",
        "week = datetime.now().isocalendar()[1]\n",
        "zip_filename = f'{strDate}_{day}_{week}_class2_images.zip'\n",
        "zip_path = os.path.join('/content', zip_filename)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, dirs, files in os.walk(class2_images_path):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), class2_images_path))\n",
        "\n",
        "# Download the zipped file\n",
        "colab_files.download(zip_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WXnmGDojsHds",
        "outputId": "6acd5016-6338-4f5c-8962-7abcb4951006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zip is already the newest version (3.0-12build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/detect/ (stored 0%)\n",
            "  adding: content/runs/detect/predict/ (stored 0%)\n",
            "  adding: content/runs/detect/predict/hdm134.png (deflated 10%)\n",
            "  adding: content/runs/detect/predict/hdm62.png (deflated 17%)\n",
            "  adding: content/runs/detect/predict/hdm56.png (deflated 18%)\n",
            "  adding: content/runs/detect/predict/hdm97.png (deflated 5%)\n",
            "  adding: content/runs/detect/predict/hdm58.png (deflated 18%)\n",
            "  adding: content/runs/detect/predict/hdm68.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm113.png (deflated 20%)\n",
            "  adding: content/runs/detect/predict/hdm74.png (deflated 7%)\n",
            "  adding: content/runs/detect/predict/hdm66.png (deflated 17%)\n",
            "  adding: content/runs/detect/predict/hdm116.png (deflated 9%)\n",
            "  adding: content/runs/detect/predict/hdm124.png (deflated 14%)\n",
            "  adding: content/runs/detect/predict/hdm64.png (deflated 17%)\n",
            "  adding: content/runs/detect/predict/hdm100.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm128.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm126.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm73.png (deflated 16%)\n",
            "  adding: content/runs/detect/predict/hdm63.png (deflated 16%)\n",
            "  adding: content/runs/detect/predict/hdm77.png (deflated 14%)\n",
            "  adding: content/runs/detect/predict/hdm101.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm117.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm110.png (deflated 3%)\n",
            "  adding: content/runs/detect/predict/hdm118.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm105.png (deflated 16%)\n",
            "  adding: content/runs/detect/predict/hdm76.png (deflated 6%)\n",
            "  adding: content/runs/detect/predict/hdm67.png (deflated 14%)\n",
            "  adding: content/runs/detect/predict/hdm65.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm71.png (deflated 8%)\n",
            "  adding: content/runs/detect/predict/hdm102.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm96.png (deflated 10%)\n",
            "  adding: content/runs/detect/predict/hdm130.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm87.png (deflated 7%)\n",
            "  adding: content/runs/detect/predict/hdm89.png (deflated 13%)\n",
            "  adding: content/runs/detect/predict/hdm129.png (deflated 13%)\n",
            "  adding: content/runs/detect/predict/hdm79.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm82.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm132.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm135.png (deflated 4%)\n",
            "  adding: content/runs/detect/predict/hdm83.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm86.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm92.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm90.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm78.png (deflated 13%)\n",
            "  adding: content/runs/detect/predict/hdm99.png (deflated 10%)\n",
            "  adding: content/runs/detect/predict/hdm108.png (deflated 16%)\n",
            "  adding: content/runs/detect/predict/hdm133.png (deflated 6%)\n",
            "  adding: content/runs/detect/predict/hdm75.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm95.png (deflated 6%)\n",
            "  adding: content/runs/detect/predict/hdm111.png (deflated 17%)\n",
            "  adding: content/runs/detect/predict/hdm119.png (deflated 7%)\n",
            "  adding: content/runs/detect/predict/hdm109.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm93.png (deflated 8%)\n",
            "  adding: content/runs/detect/predict/hdm123.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm84.png (deflated 4%)\n",
            "  adding: content/runs/detect/predict/hdm112.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm125.png (deflated 9%)\n",
            "  adding: content/runs/detect/predict/hdm120.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm81.png (deflated 6%)\n",
            "  adding: content/runs/detect/predict/hdm70.png (deflated 8%)\n",
            "  adding: content/runs/detect/predict/hdm104.png (deflated 7%)\n",
            "  adding: content/runs/detect/predict/hdm98.png (deflated 13%)\n",
            "  adding: content/runs/detect/predict/hdm91.png (deflated 19%)\n",
            "  adding: content/runs/detect/predict/hdm136.png (deflated 18%)\n",
            "  adding: content/runs/detect/predict/hdm106.png (deflated 10%)\n",
            "  adding: content/runs/detect/predict/hdm88.png (deflated 10%)\n",
            "  adding: content/runs/detect/predict/hdm127.png (deflated 11%)\n",
            "  adding: content/runs/detect/predict/hdm85.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm94.png (deflated 12%)\n",
            "  adding: content/runs/detect/predict/hdm121.png (deflated 9%)\n",
            "  adding: content/runs/detect/predict/hdm114.png (deflated 9%)\n",
            "  adding: content/runs/detect/predict/hdm115.png (deflated 10%)\n",
            "  adding: content/runs/detect/predict/hdm131.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm69.png (deflated 10%)\n",
            "  adding: content/runs/detect/predict/hdm103.png (deflated 10%)\n",
            "  adding: content/runs/detect/predict/hdm122.png (deflated 15%)\n",
            "  adding: content/runs/detect/predict/hdm72.png (deflated 8%)\n",
            "  adding: content/runs/detect/predict/hdm80.png (deflated 8%)\n",
            "  adding: content/runs/detect/predict/hdm36.png (deflated 16%)\n",
            "  adding: content/runs/detect/predict/hdm107.png (deflated 17%)\n",
            "  adding: content/runs/detect/val/ (stored 0%)\n",
            "  adding: content/runs/detect/val/val_batch0_labels.jpg (deflated 26%)\n",
            "  adding: content/runs/detect/val/R_curve.png (deflated 15%)\n",
            "  adding: content/runs/detect/val/confusion_matrix.png (deflated 31%)\n",
            "  adding: content/runs/detect/val/P_curve.png (deflated 12%)\n",
            "  adding: content/runs/detect/val/confusion_matrix_normalized.png (deflated 27%)\n",
            "  adding: content/runs/detect/val/PR_curve.png (deflated 22%)\n",
            "  adding: content/runs/detect/val/val_batch0_pred.jpg (deflated 26%)\n",
            "  adding: content/runs/detect/val/F1_curve.png (deflated 13%)\n",
            "  adding: content/runs/detect/train/ (stored 0%)\n",
            "  adding: content/runs/detect/train/train_batch1.jpg (deflated 21%)\n",
            "  adding: content/runs/detect/train/labels.jpg (deflated 37%)\n",
            "  adding: content/runs/detect/train/results.csv (deflated 85%)\n",
            "  adding: content/runs/detect/train/results.png (deflated 7%)\n",
            "  adding: content/runs/detect/train/train_batch0.jpg (deflated 25%)\n",
            "  adding: content/runs/detect/train/train_batch2.jpg (deflated 17%)\n",
            "  adding: content/runs/detect/train/val_batch0_labels.jpg (deflated 26%)\n",
            "  adding: content/runs/detect/train/train_batch162.jpg (deflated 34%)\n",
            "  adding: content/runs/detect/train/R_curve.png (deflated 15%)\n",
            "  adding: content/runs/detect/train/events.out.tfevents.1716297642.b7f617f5061a.1850.0 (deflated 90%)\n",
            "  adding: content/runs/detect/train/confusion_matrix.png (deflated 31%)\n",
            "  adding: content/runs/detect/train/P_curve.png (deflated 12%)\n",
            "  adding: content/runs/detect/train/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train/weights/last.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train/weights/best.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train/train_batch161.jpg (deflated 26%)\n",
            "  adding: content/runs/detect/train/confusion_matrix_normalized.png (deflated 27%)\n",
            "  adding: content/runs/detect/train/PR_curve.png (deflated 22%)\n",
            "  adding: content/runs/detect/train/labels_correlogram.jpg (deflated 43%)\n",
            "  adding: content/runs/detect/train/train_batch160.jpg (deflated 30%)\n",
            "  adding: content/runs/detect/train/args.yaml (deflated 53%)\n",
            "  adding: content/runs/detect/train/val_batch0_pred.jpg (deflated 26%)\n",
            "  adding: content/runs/detect/train/F1_curve.png (deflated 13%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_add343a5-86f5-4986-adad-0cf9fdb6812d\", \"runs.zip\", 65133184)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive (optional)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Ensure zip is installed (most likely already installed)\n",
        "!apt-get install zip\n",
        "\n",
        "# Step 3: Zip the /content/runs directory\n",
        "!zip -r /content/runs.zip /content/runs\n",
        "\n",
        "# Step 4: Download the zipped file\n",
        "from google.colab import files\n",
        "files.download('/content/runs.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpH_t0vkAVVg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRcwPkO5VBl5"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install necessary libraries and Tesseract OCR\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install moviepy pytesseract opencv-python-headless\n",
        "\n",
        "# Step 2: Import required libraries\n",
        "import moviepy.editor as mp\n",
        "import pytesseract\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Set the Tesseract executable path\n",
        "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "\n",
        "# Step 3: Define paths\n",
        "video_path = \"/content/drive/MyDrive/group Facebook/Screen Recording 2024-05-20 at 19.25.26.mov\"\n",
        "text_path = \"/content/transcribed_text.txt\"\n",
        "\n",
        "# Step 4: Function to extract text from frames\n",
        "def extract_text_from_video(video_path):\n",
        "    video = mp.VideoFileClip(video_path)\n",
        "    text = \"\"\n",
        "    for frame in video.iter_frames():\n",
        "        # Convert frame to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        # Apply OCR to the frame\n",
        "        frame_text = pytesseract.image_to_string(gray_frame)\n",
        "        text += frame_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Step 5: Save extracted text to a file\n",
        "def save_text_to_file(text, text_path):\n",
        "    with open(text_path, 'w') as file:\n",
        "        file.write(text)\n",
        "\n",
        "# Step 6: Execute the functions\n",
        "extracted_text = extract_text_from_video(video_path)\n",
        "save_text_to_file(extracted_text, text_path)\n",
        "\n",
        "# Step 7: Output the path of the text file\n",
        "print(f\"Extracted text saved to: {text_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBcfQte_kS1z",
        "outputId": "fd2797d3-da90-4d2d-a49d-f645f6d41adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "40YsH_GINdBV",
        "outputId": "001ff9a5-83b9-48de-a7dc-3df116b9e8c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        },
        {
          "ename": "TesseractNotFoundError",
          "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msubprocess_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    972\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1862\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tesseract'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-946de5f53f0a>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Step 6: Execute the functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mextracted_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0msave_text_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-946de5f53f0a>\u001b[0m in \u001b[0;36mextract_text_from_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgray_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Apply OCR to the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mframe_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mframe_text\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     }[output_type]()\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    286\u001b[0m         }\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{kwargs['output_filename_base']}{extsep}{extension}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTesseractNotFoundError\u001b[0m: tesseract is not installed or it's not in your PATH. See README file for more information."
          ]
        }
      ],
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install moviepy pytesseract opencv-python-headless\n",
        "\n",
        "# Step 2: Import required libraries\n",
        "import moviepy.editor as mp\n",
        "import pytesseract\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Step 3: Define paths\n",
        "video_path = \"/content/drive/MyDrive/group Facebook/Screen Recording 2024-05-20 at 19.25.26.mov\"\n",
        "text_path = \"/content/transcribed_text.txt\"\n",
        "\n",
        "# Step 4: Function to extract text from frames\n",
        "def extract_text_from_video(video_path):\n",
        "    video = mp.VideoFileClip(video_path)\n",
        "    text = \"\"\n",
        "    for frame in video.iter_frames():\n",
        "        # Convert frame to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        # Apply OCR to the frame\n",
        "        frame_text = pytesseract.image_to_string(gray_frame)\n",
        "        text += frame_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Step 5: Save extracted text to a file\n",
        "def save_text_to_file(text, text_path):\n",
        "    with open(text_path, 'w') as file:\n",
        "        file.write(text)\n",
        "\n",
        "# Step 6: Execute the functions\n",
        "extracted_text = extract_text_from_video(video_path)\n",
        "save_text_to_file(extracted_text, text_path)\n",
        "\n",
        "# Step 7: Output the path of the text file\n",
        "print(f\"Extracted text saved to: {text_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJTrnrEibOjq",
        "outputId": "f4db7b4f-851e-4a97-eb6e-dd253bf802f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Working Directory: /content\n",
            "Contents of the current directory:\n",
            "['.config', 'drive', 'sample_data']\n",
            "'runs/detect/' directory not found.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Step 1: Check the current working directory\n",
        "current_directory = os.getcwd()\n",
        "print(f\"Current Working Directory: {current_directory}\")\n",
        "\n",
        "# Step 2: List the contents of the current directory\n",
        "print(\"Contents of the current directory:\")\n",
        "print(os.listdir(current_directory))\n",
        "\n",
        "# Step 3: Define the path to the 'runs/detect/' directory\n",
        "detect_directory = os.path.join(current_directory, 'runs', 'detect')\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(detect_directory):\n",
        "    print(f\"'runs/detect/' directory found at: {detect_directory}\")\n",
        "    # List the contents of the 'runs/detect/' directory\n",
        "    print(\"Contents of the 'runs/detect/' directory:\")\n",
        "    print(os.listdir(detect_directory))\n",
        "else:\n",
        "    print(\"'runs/detect/' directory not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "JBokeJf_PWnb",
        "outputId": "9d1fd00b-fd7b-4017-c927-041bab8ad977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 229 kB in 4s (51.1 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-951cb01a0564>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Step 6: Execute the functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mextracted_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0msave_text_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-951cb01a0564>\u001b[0m in \u001b[0;36mextract_text_from_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mgray_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Apply OCR to the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mframe_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mframe_text\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mimage_to_string\u001b[0;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     return {\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTES\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDICT\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun_and_get_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     }[output_type]()\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    286\u001b[0m         }\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mrun_tesseract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{kwargs['output_filename_base']}{extsep}{extension}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtimeout_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTesseractError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytesseract/pytesseract.py\u001b[0m in \u001b[0;36mtimeout_manager\u001b[0;34m(proc, seconds)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2019\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Step 1: Install necessary libraries and Tesseract OCR\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install moviepy pytesseract opencv-python-headless\n",
        "\n",
        "# Step 2: Import required libraries\n",
        "import moviepy.editor as mp\n",
        "import pytesseract\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Set the Tesseract executable path\n",
        "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "\n",
        "# Step 3: Define paths\n",
        "video_path = \"/content/drive/MyDrive/group Facebook/Screen Recording 2024-05-20 at 19.25.26.mov\"\n",
        "text_path = \"/content/transcribed_text.txt\"\n",
        "\n",
        "# Step 4: Function to extract text from frames\n",
        "def extract_text_from_video(video_path):\n",
        "    video = mp.VideoFileClip(video_path)\n",
        "    text = \"\"\n",
        "    for frame in video.iter_frames():\n",
        "        # Convert frame to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        # Apply OCR to the frame\n",
        "        frame_text = pytesseract.image_to_string(gray_frame)\n",
        "        text += frame_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Step 5: Save extracted text to a file\n",
        "def save_text_to_file(text, text_path):\n",
        "    with open(text_path, 'w') as file:\n",
        "        file.write(text)\n",
        "\n",
        "# Step 6: Execute the functions\n",
        "extracted_text = extract_text_from_video(video_path)\n",
        "save_text_to_file(extracted_text, text_path)\n",
        "\n",
        "# Step 7: Output the path of the text file\n",
        "print(f\"Extracted text saved to: {text_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}